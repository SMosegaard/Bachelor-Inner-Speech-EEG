{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7605c325-7a18-4f9a-b59e-b636ae888ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Activate virtual envoriment:\n",
    "\n",
    "import os\n",
    "path='/work/807122' # Remember to change kernel to virt_env!!!\n",
    "os.chdir(path)\n",
    "!./activate.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2408c17a-7e4e-4304-a245-14e68744b87c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Check that im are in the right environment\n",
    "\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import nilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58798006-4602-4439-877b-3d59fe584281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T09:13:26.624957Z",
     "iopub.status.busy": "2023-12-20T09:13:26.624529Z",
     "iopub.status.idle": "2023-12-20T09:13:34.055761Z",
     "shell.execute_reply": "2023-12-20T09:13:34.054614Z",
     "shell.execute_reply.started": "2023-12-20T09:13:26.624934Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing modules\n",
    "import os\n",
    "import pip\n",
    "import numpy as np\n",
    "import mne\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "importlib.reload(plt)\n",
    "\n",
    "import pylab, seaborn as sns\n",
    "from scipy.stats import ttest_rel, sem\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split, StratifiedKFold, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, make_scorer, accuracy_score, f1_score, precision_recall_fscore_support\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mne.decoding import (SlidingEstimator, GeneralizingEstimator, Scaler,\n",
    "                          cross_val_multiscore, LinearModel, get_coef,Vectorizer, CSP)\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from scipy.stats import binom_test\n",
    "\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e321908d-29a1-44e0-8842-8bf7619e274a",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e99b5b-a186-451b-8b58-4dabf4a376be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data in with a hierarchical structure: each participants and respectively, their three sessions\n",
    "\n",
    "#data_dir = '/work/823001/ds003626-download/derivatives/'\n",
    "data_dir = '/work/data/ds003626-download/derivatives/'\n",
    "\n",
    "# Empty folder \n",
    "all_data = []\n",
    "\n",
    "# Listing all folders in data_dir that start with \"sub-\"\n",
    "participants = [folder for folder in os.listdir(data_dir) if folder.startswith('sub-')]\n",
    "\n",
    "# Define a list of modality labels (i.e., trial class)\n",
    "modality_label = ['Arriba', 'Abajo', 'Derecha', 'Izquierda']\n",
    "\n",
    "# Create lists, that will be filled up with all participants' data\n",
    "participants_pronounced = []\n",
    "participants_inner = []\n",
    "participants_visualized = []\n",
    "\n",
    "# Loop through each participant's data\n",
    "for participant in participants:\n",
    "    participant_dir = os.path.join(data_dir, participant)\n",
    "    \n",
    "    # Create empty lists to store participant and session data (these resets for each participants)\n",
    "    session_pronounced = []\n",
    "    session_inner = []\n",
    "    session_visualized = []\n",
    "    \n",
    "    # Loop through all sessions for each participant in part_dir\n",
    "    for session_num in range(1, 4):  #session \"ses-01\", \"ses-02\", and \"ses-03\"\n",
    "        session_dir = os.path.join(participant_dir, f'ses-0{session_num}')\n",
    "        \n",
    "        # [] = list, {} = dictonary \n",
    "        event_dat = []\n",
    "        event_data = {}\n",
    "        event_data_session = {}\n",
    "        \n",
    "        # Create dictionaries for the three conditions\n",
    "        pronounced_con = {} # column 2 == 0\n",
    "        inner_con = {} # column 2 == 1\n",
    "        visualized_con = {} # column 2 == 2\n",
    "        \n",
    "        # .dat file path\n",
    "        dat_file_path = os.path.join(session_dir, f'{participant}_ses-0{session_num}_events.dat')\n",
    "    \n",
    "       # if os.path.exists(dat_file_path):\n",
    "        ## i have commented this line of code out, as I want to recieve an error if a event.dat file is missing\n",
    "        with open(dat_file_path, \"rb\") as file: # \"rb\" = read in binary format\n",
    "            event_dat = pickle.load(file)\n",
    "       \n",
    "        # loop over the elements of the modality_label list (match labels and events.dat)\n",
    "        # filter the event_dat based on the values of column 2 (class/modality)\n",
    "        for l, label in enumerate(modality_label):\n",
    "            event_data[label] = event_dat[event_dat[:,1]==l,:] \n",
    "        \n",
    "        # now event_data contains 4 arrays (one for each of the modalities)\n",
    " \n",
    "        # EEG .fif file path\n",
    "        eeg_file_path = os.path.join(session_dir, f'{participant}_ses-0{session_num}_eeg-epo.fif')\n",
    "        \n",
    "        #if os.path.exists(eeg_file_path):\n",
    "        ## same goes for the eeg.fif files\n",
    "        epochs = mne.read_epochs(eeg_file_path, preload=True)\n",
    "        \n",
    "        # Check for epochs .fif and events .dat file correspondence (they will be matched on timestamps)\n",
    "        # Correspondence = 0\n",
    "        if not sum(epochs.events[:,0]-event_dat[:,0])==0:\n",
    "            print(\"MISMATCH IN EPOCHS/DAT FILE TIMESTAMPS! {}\".format(session_dir))\n",
    "            break # Naturally, we want to stop the loop, if an error / mismatch occurs \n",
    "        \n",
    "        # Specify channel location (EEG data acquired used BioSemi128)\n",
    "        montage = mne.channels.make_standard_montage('biosemi128')\n",
    "        epochs.set_montage(montage, verbose=False)\n",
    "        \n",
    "        # Loop over each condition (0, 1, 2) in modaility_label in data-file\n",
    "        for label in modality_label:\n",
    "            pronounced_con[label] = epochs[label][event_data[label][:, 2] == 0]\n",
    "            inner_con[label] = epochs[label][event_data[label][:, 2] == 1]\n",
    "            visualized_con[label] = epochs[label][event_data[label][:, 2] == 2]\n",
    "        \n",
    "            # Same sanity-check for the conditions and modalities\n",
    "            if not (sum(pronounced_con[label].events[:,0]-event_data[label][event_data[label][:, 2] == 0, 0])==0 or \n",
    "                    sum(inner_con[label].events[:,0]-event_data[label][event_data[label][:, 2] == 1, 0])==0 or\n",
    "                    sum(visualized_con[label].events[:,0]-event_data[label][event_data[label][:, 2] == 2, 0])==0):\n",
    "                print(\"MISMATCH IN LABEL EPOCHS / LABEL DAT FILE TIMESTAMPS! {}: {}\".format(session_dir, label))\n",
    "                break\n",
    "        \n",
    "        session_pronounced.append(pronounced_con)\n",
    "        session_inner.append(inner_con)\n",
    "        session_visualized.append(visualized_con)\n",
    "     \n",
    "    # Empty dictionaries to store concatenated data for each condition\n",
    "    concatenated_pronounced = {}\n",
    "    concatenated_inner = {}\n",
    "    concatenated_visualized = {}\n",
    "    \n",
    "    # Loop through the modality labels\n",
    "    for label in modality_label:\n",
    "        # Concatenate the sessions for the pronounced con\n",
    "        pronounced_sessions = [sessions[label] for sessions in session_pronounced]\n",
    "        concatenated_pronounced[label] = mne.concatenate_epochs(pronounced_sessions)\n",
    "\n",
    "        # Concatenate the sessions for the inner con\n",
    "        inner_sessions = [sessions[label] for sessions in session_inner]\n",
    "        concatenated_inner[label] = mne.concatenate_epochs(inner_sessions)\n",
    "\n",
    "        # Concatenate the sessions for the visualized \n",
    "        visualized_sessions = [sessions[label] for sessions in session_visualized]\n",
    "        concatenated_visualized[label] = mne.concatenate_epochs(visualized_sessions)\n",
    "    \n",
    "    # Combine back into an epochs object with the four directions as conditions\n",
    "    # ... now I will be able to analyze all 4 directions/labels over all 3 sessions for inner speech in the same object\n",
    "    conc_pronounced = mne.concatenate_epochs([concatenated_pronounced[label] for label in modality_label])\n",
    "    conc_inner = mne.concatenate_epochs([concatenated_inner[label] for label in modality_label])\n",
    "    conc_visualized = mne.concatenate_epochs([concatenated_visualized[label] for label in modality_label])\n",
    "    \n",
    "    # Print length of participant_data to check if it's empty\n",
    "    print(f\"Participant {participant}: Number of sessions with EEG data: {len(concatenated_pronounced)}\")\n",
    "    \n",
    "    # Append the EEG data to the participant_data list\n",
    "    participants_pronounced.append(conc_pronounced)  \n",
    "    participants_inner.append(conc_inner)  \n",
    "    participants_visualized.append(conc_visualized)  \n",
    "        \n",
    "    # Append the epochs to the all_data list\n",
    "    #all_data.append(epochs)\n",
    "            \n",
    "# Print length of all_data to check if it's empty \n",
    "print(f\"Total number of participants with EEG data: {len(participants_pronounced)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea72a4d8-b683-4ba6-b997-ef29c1684251",
   "metadata": {},
   "source": [
    "### 1.2 Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27e1468-8f85-43f7-910d-231c7dda649a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "low_pass = 40  # Lets all frequencies lower than 40 Hz pass through\n",
    "\n",
    "# Loop through all participants' conditions and apply low-pass filter of 40 Hz\n",
    "for i in range(0, 10):  # Beacuse I have 10 participants        \n",
    "    participants_pronounced[i] = participants_pronounced[i].filter(None, low_pass)\n",
    "\n",
    "for i in range(0, 10):      \n",
    "    participants_inner[i] = participants_inner[i].filter(None, low_pass)\n",
    "\n",
    "for i in range(0, 10):      \n",
    "    participants_visualized[i] = participants_visualized[i].filter(None, low_pass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a422a627-71ff-4e69-821f-6fc9bbbcc603",
   "metadata": {},
   "source": [
    "### 1.3 Reject criteria + bad channels + Interpolate bad channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a7cecc-4d18-4929-bdba-c7f828961db8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T09:19:28.825333Z",
     "iopub.status.busy": "2023-12-20T09:19:28.825085Z",
     "iopub.status.idle": "2023-12-20T09:19:28.835936Z",
     "shell.execute_reply": "2023-12-20T09:19:28.834474Z",
     "shell.execute_reply.started": "2023-12-20T09:19:28.825312Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The following channels will be removed, as they caused too many epochs to be rejected:\n",
    "\n",
    "participants_pronounced[1].info['bads'] = ['D24', 'D18', 'B4', 'B2', 'D9', 'D10', 'A5','D14', 'A30', 'D20', 'B24'] \n",
    "participants_inner[1].info['bads'] = ['D24', 'D18', 'B4', 'B2', 'D9', 'D10', 'A5', 'D14', 'A30', 'D20', 'B24'] \n",
    "participants_visualized[1].info['bads'] = ['D24', 'D18', 'B4', 'B2', 'D9', 'D10', 'A5'] \n",
    "\n",
    "participants_pronounced[2].info['bads'] = ['A25', 'A27']\n",
    "participants_inner[2].info['bads'] = ['A25', 'A27']\n",
    "participants_visualized[2].info['bads'] = ['A25', 'A27']\n",
    "\n",
    "participants_pronounced[4].info['bads'] =['B23', 'B24']\n",
    "participants_inner[4].info['bads'] =['B23', 'B24']\n",
    "participants_visualized[4].info['bads'] =['B26']\n",
    "\n",
    "participants_pronounced[5].info['bads'] =['D6', 'D8', 'D9', 'D10']\n",
    "participants_inner[5].info['bads'] =['D6', 'D8', 'D9', 'D10']\n",
    "participants_visualized[5].info['bads'] =['D6', 'D8', 'D9', 'D10']\n",
    "\n",
    "participants_pronounced[9].info['bads'] = ['D1', 'C1', 'B20', 'A1', 'A2', 'A3', 'B1', 'C2']\n",
    "participants_inner[9].info['bads'] = ['D1', 'C1', 'B20', 'A1', 'A2', 'A3', 'B1', 'C2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4b2b7e-d26c-4b2c-a8b1-0b58d8275cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Interpolate bad channels\n",
    "# Before doing classification, it is important, that my data maintain identical dimensionalities for all subjects\n",
    "# As the same channels are not bad for all subjects, I will reconstruct bad channels by interpolating its signal\n",
    "# based on the signals of the good sensors around them\n",
    "\n",
    "for sub in participants_pronounced:\n",
    "    sub.copy().interpolate_bads(reset_bads=False)\n",
    "\n",
    "for sub in participants_inner:\n",
    "    sub.copy().interpolate_bads(reset_bads=False)\n",
    "\n",
    "for sub in participants_visualized:\n",
    "    sub.copy().interpolate_bads(reset_bads=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5c1357-9040-4079-9ce7-47dba8784485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rejecting EEG epochs above 200 microvolts.\n",
    "reject_criteria = dict(eeg=200e-6)\n",
    "\n",
    "# Loop through the list of EpochsArray objects for each participant in each condtion\n",
    "for sub in participants_pronounced:\n",
    "    sub.drop_bad(reject=reject_criteria)\n",
    "    \n",
    "for sub in participants_inner:\n",
    "    sub.drop_bad(reject=reject_criteria)\n",
    "\n",
    "for sub in participants_visualized:\n",
    "    sub.drop_bad(reject=reject_criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79455ac2-8167-41b9-8c65-91d5ae658e29",
   "metadata": {},
   "source": [
    "### 1.5 Time window for epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e10e489-f9c5-4636-a3e8-bd0a3ff947d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T09:19:52.421399Z",
     "iopub.status.busy": "2023-12-20T09:19:52.420948Z",
     "iopub.status.idle": "2023-12-20T09:19:57.514823Z",
     "shell.execute_reply": "2023-12-20T09:19:57.513351Z",
     "shell.execute_reply.started": "2023-12-20T09:19:52.421370Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pronounced vs inner speech:\n",
    "## I only want to classify signal from the action interval (where the participant had to imagine or pronounce speech),\n",
    "## I have to define the temporal epoch, which I will use as input for the classifier.\n",
    "\n",
    "action_participants_pronounced = []\n",
    "action_participants_inner = []\n",
    "action_participants_visualized = []\n",
    "\n",
    "action_tmin = 1\n",
    "action_tmax = 3.5\n",
    "\n",
    "for sub in participants_pronounced:\n",
    "    time_windowed_data = sub.copy().crop(tmin=action_tmin, tmax=action_tmax)\n",
    "    action_participants_pronounced.append(time_windowed_data)\n",
    "\n",
    "for sub in participants_inner:\n",
    "    time_windowed_data = sub.copy().crop(tmin=action_tmin, tmax=action_tmax)\n",
    "    action_participants_inner.append(time_windowed_data)\n",
    "\n",
    "for sub in participants_visualized:\n",
    "    time_windowed_data = sub.copy().crop(tmin=action_tmin, tmax=action_tmax)\n",
    "    action_participants_visualized.append(time_windowed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8405d910-5b4b-4687-947d-4a8e357ca3ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############ For the rest vs inner condition ############\n",
    "## as the timestamps dont match, I apply numpy.concatenate directly on my numpy arrays ##\n",
    "# No need to apply RandomOverSampler as this data is balanced\n",
    "\n",
    "action_participants_inner_2 = []\n",
    "rest_participants_inner = []\n",
    "\n",
    "rest_tmin = 3.5\n",
    "rest_tmax = 4\n",
    "\n",
    "action_tmin_2 = 1\n",
    "action_tmax_2 = 1.5\n",
    "\n",
    "for sub in participants_inner:\n",
    "    time_windowed_data = sub.copy().crop(tmin=action_tmin_2, tmax=action_tmax_2)\n",
    "    action_participants_inner_2.append(time_windowed_data.get_data())\n",
    "\n",
    "for sub in participants_inner:\n",
    "    rest_time_window_data = sub.copy().crop(tmin=rest_tmin, tmax=rest_tmax)\n",
    "    rest_participants_inner.append(rest_time_window_data.get_data())\n",
    "\n",
    "ri_balanced_X = []\n",
    "ri_balanced_y = []\n",
    "    \n",
    "for participant_idx in range(len(participants_inner)):\n",
    "    X_rest = rest_participants_inner[participant_idx]\n",
    "    X_action = action_participants_inner_2[participant_idx]\n",
    "    \n",
    "    y_rest = np.zeros(X_rest.shape[0])\n",
    "    y_action = np.ones(X_action.shape[0])\n",
    "    \n",
    "    # Concatenate numpy arrays directly\n",
    "    X_participant = np.concatenate([X_rest, X_action], axis=0)\n",
    "    y_participant = np.concatenate([y_rest, y_action], axis=0)\n",
    "\n",
    "    class_balanced = Counter(y_participant)\n",
    "    print(f'Participant {participant_idx}: {class_balanced}')\n",
    "    \n",
    "    # Reshape the resampled data back to 3D format\n",
    "    #X_3D = X_over.reshape(-1, 128, 641) # (trials, channels, timepoints)\n",
    "    \n",
    "    ri_balanced_X.append(X_participant)\n",
    "    ri_balanced_y.append(y_participant)\n",
    "    \n",
    "ri_X_overall = np.vstack(ri_balanced_X) # type = numpy.ndarray\n",
    "ri_y_overall = np.hstack(ri_balanced_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5352fa7-8945-44a5-9395-308a9d004ff8",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6043739-0d1e-46dc-88c3-6b5c3431f263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "balanced_X_sub = []\n",
    "balanced_y_sub = []\n",
    "\n",
    "X_sub = mne.concatenate_epochs([action_participants_pronounced[0], action_participants_inner[0]]).get_data() # (309, 128, 641)\n",
    "X_sub = X_sub.reshape(-1, 128 * 641) # (309, 82048)\n",
    "y_sub = np.concatenate([np.zeros(len(action_participants_pronounced[0])), np.ones(len(action_participants_inner[0]))]) # (309,)\n",
    "\n",
    "class_before = Counter(y_sub)\n",
    "print(f'Participant 0: {class_before}') # Print y before applying the random oversampler\n",
    "\n",
    "# Apply RandomOverSampler for the current participant\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_sub_over, y_sub_over = oversample.fit_resample(X_sub, y_sub) \n",
    "\n",
    "class_after = Counter(y_sub_over)\n",
    "print(f'Participant 0: {class_after}') # Counter({0.0: 204, 1.0: 204})\n",
    "\n",
    "X_sub_over = X_sub_over.reshape((-1, 128, 641))\n",
    "\n",
    "balanced_X_sub.append(X_sub_over) # type = list\n",
    "balanced_y_sub.append(y_sub_over)\n",
    "\n",
    "X_participant = balanced_X_sub[0] # type = numpy.ndarray\n",
    "y_participant = balanced_y_sub[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b160318-1a76-4377-a6f4-e39da2fcea05",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4482c1-10b7-4da6-a44d-9b7fcbe73486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=5,test_size=0.2,random_state=124) #random_data = set.seed() (to ensure reproducibility)\n",
    "\n",
    "# create a classifier with a scaling function and l2 penalty\n",
    "clf = make_pipeline(RobustScaler(), \n",
    "                    LinearModel(LogisticRegression(penalty='l2',solver='saga',max_iter=1000)))\n",
    "\n",
    "time_decod = SlidingEstimator(clf, scoring='roc_auc')\n",
    "\n",
    "scores = cross_val_multiscore(time_decod, X_participant, y_participant, cv=cv)\n",
    "\n",
    "scores_mean = np.mean(scores, axis=0)\n",
    "\n",
    "best_timepoint = np.argmax(scores_mean)\n",
    "print(\"The most informative timepoint is:\",best_timepoint)\n",
    "\n",
    "time_decod.fit(X_participant, y_participant)\n",
    "\n",
    "coef = get_coef(time_decod, 'patterns_',inverse_transform=True)\n",
    "\n",
    "preds = time_decod.predict_proba(X_participant)[:,best_timepoint, :]\n",
    "\n",
    "y_preds = [np.argmax(trial) for trial in preds]\n",
    "print(y_preds[:10])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_participant, y_preds, labels = [0,1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['pronounced speech', 'inner speech']) \n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "clf_report = classification_report(y_participant, y_preds, target_names = ['pronounced speech', 'inner speech']) \n",
    "print(clf_report)\n",
    "\n",
    "accuracy = accuracy_score(y_participant, y_preds)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "loss = log_loss(y_participant, preds)\n",
    "print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e39232-f292-4093-8462-bffd3d22e783",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "significance_test = binomtest(k =191+197, n= 476,p=0.5)\n",
    "significance_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b65e8-a982-4820-8c97-32bfd221d3a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_permutations = 1000\n",
    "permutation_scores = []\n",
    "num_classes = 2\n",
    "\n",
    "for _ in range(num_permutations):\n",
    "    shuffled_labels = shuffle(y_preds) # or all_predicted_labels?\n",
    "    accuracy = accuracy_score(y_preds, shuffled_labels)\n",
    "    permutation_scores.append(accuracy)\n",
    "\n",
    "p_value = (np.sum(np.array(permutation_scores) >= accuracy) + 1) / (num_permutations + 1)\n",
    "print(p_value)\n",
    "\n",
    "plt.hist(permutation_scores, 20, label='Permutation scores', edgecolor='black')\n",
    "ylim = plt.ylim()\n",
    "plt.plot(2 * [accuracy], ylim, '--g', linewidth=3, label=f'Actual Accuracy (p-value {p_value:.4f})')\n",
    "plt.plot(2 * [1. / num_classes], ylim, '--k', linewidth=3, label='Chance level')\n",
    "plt.ylim(ylim)\n",
    "plt.legend()\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Permutation Test for Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f09a21-991f-429d-beb5-2119a3c5da53",
   "metadata": {},
   "source": [
    "#### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8892fdf-f468-4d15-8f6f-0deb1fc987a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(X_participant.shape)\n",
    "print(y_participant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb8ae3-58fa-42c7-b375-2c6db523ec2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier_svm = make_pipeline(Vectorizer(), RobustScaler(), SVC(kernel='rbf', C=1))\n",
    "cv_score_svm = cross_val_score(classifier_svm, X_participant, y_participant, cv=5)\n",
    "\n",
    "# Print mean prediction score\n",
    "print('Mean prediction score for SVM:', np.mean(cv_score_svm))\n",
    "\n",
    "# Classification report for SVM\n",
    "y_pred_svm = cross_val_predict(classifier_svm, X_participant, y_participant, cv=5)\n",
    "print('Classification Report for SVM:')\n",
    "print(classification_report(y_participant, y_pred_svm))\n",
    "\n",
    "# Confusion matrix for SVM\n",
    "conf_matrix_svm = confusion_matrix(y_participant, y_pred_svm)\n",
    "print('Confusion Matrix for SVM:')\n",
    "print(conf_matrix_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935caa13-5339-468e-acbe-7ec27b22ad62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "significance_test = binomtest(k =188+201, n= 448,p=0.5)\n",
    "significance_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b2d6b-2f29-4d48-8c6d-ad4c351a127a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_permutations = 1000\n",
    "permutation_scores = []\n",
    "num_classes = np.unique(y_sub_over).size\n",
    "\n",
    "for _ in range(num_permutations):\n",
    "    shuffled_labels = shuffle(y_pred_svm) # or all_predicted_labels?\n",
    "    accuracy = accuracy_score(y_pred_svm, shuffled_labels)\n",
    "    permutation_scores.append(accuracy)\n",
    "\n",
    "p_value = (np.sum(np.array(permutation_scores) >= accuracy) + 1) / (num_permutations + 1)\n",
    "print(p_value)\n",
    "\n",
    "plt.hist(permutation_scores, 20, label='Permutation scores', edgecolor='black')\n",
    "ylim = plt.ylim()\n",
    "plt.plot(2 * [accuracy], ylim, '--g', linewidth=3, label=f'Actual Accuracy (p-value {p_value:.4f})')\n",
    "plt.plot(2 * [1. / num_classes], ylim, '--k', linewidth=3, label='Chance level')\n",
    "plt.ylim(ylim)\n",
    "plt.legend()\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Permutation Test for Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057b67b6-9ae3-4138-9055-22554b5fe1da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b309f37c-af12-4fa4-900c-30c576d08562",
   "metadata": {},
   "source": [
    "### GaussainNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1cb619-0e0b-4806-b993-6322419db0d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(X_participant.shape)\n",
    "print(y_participant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac609833-097e-4b71-b8ee-5f99fcb477f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T16:47:20.708988Z",
     "iopub.status.busy": "2023-11-29T16:47:20.707720Z",
     "iopub.status.idle": "2023-11-29T16:47:20.865712Z",
     "shell.execute_reply": "2023-11-29T16:47:20.864633Z",
     "shell.execute_reply.started": "2023-11-29T16:47:20.708926Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = GaussianNB()\n",
    "X = RobustScaler().fit_transform(X_participant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd1ca78-77dc-40c9-b154-0a17c7ad5bbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T16:47:21.841921Z",
     "iopub.status.busy": "2023-11-29T16:47:21.841097Z",
     "iopub.status.idle": "2023-11-29T16:47:22.987829Z",
     "shell.execute_reply": "2023-11-29T16:47:22.986926Z",
     "shell.execute_reply.started": "2023-11-29T16:47:21.841861Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(GaussianNB(), X_participant, y_participant, cv=5)\n",
    "print('Score of each individual cross-validation fold:', cv_score)\n",
    "print('Mean prediction score:',np.mean(cv_score))\n",
    "\n",
    "# Classification report\n",
    "y_pred = cross_val_predict(GaussianNB(), X_participant, y_participant, cv=5)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_participant, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_participant, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa69ef7-4be2-402d-b946-3a7098e4b654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T16:47:23.745818Z",
     "iopub.status.busy": "2023-11-29T16:47:23.745094Z",
     "iopub.status.idle": "2023-11-29T16:47:50.914862Z",
     "shell.execute_reply": "2023-11-29T16:47:50.913779Z",
     "shell.execute_reply.started": "2023-11-29T16:47:23.745716Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import permutation_test_score\n",
    "\n",
    "score, permutation_scores, pvalue= permutation_test_score(\n",
    "    GaussianNB(), X_participant, y_participant, cv=5, n_permutations=50, \n",
    "    n_jobs=1, random_state=0, verbose=0, scoring=None)\n",
    "print(\"Classification Accuracy: %s (pvalue : %s)\" % (score, pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ba774a-0353-4f3d-b711-2b4a5fec45f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T16:47:50.974759Z",
     "iopub.status.busy": "2023-11-29T16:47:50.974575Z",
     "iopub.status.idle": "2023-11-29T16:47:51.178664Z",
     "shell.execute_reply": "2023-11-29T16:47:51.177897Z",
     "shell.execute_reply.started": "2023-11-29T16:47:50.974740Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_classes = np.unique(y_participant).size\n",
    "\n",
    "plt.hist(permutation_scores, 20, label='Permutation scores',\n",
    "         edgecolor='black')\n",
    "ylim = plt.ylim()\n",
    "plt.plot(2 * [score], ylim, '--g', linewidth=3,\n",
    "         label='Classification Score'\n",
    "         ' (pvalue %s)' % pvalue)\n",
    "plt.plot(2 * [1. / n_classes], ylim, '--k', linewidth=3, label='Chance level')\n",
    "\n",
    "plt.ylim(ylim)\n",
    "plt.legend()\n",
    "plt.xlabel('Score')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
